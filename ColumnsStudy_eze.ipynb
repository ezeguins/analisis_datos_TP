{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "#import import_ipynb\n",
    "import TP_WeatherAUS as TP\n",
    "import importlib\n",
    "importlib.reload(TP)\n",
    "# Se ignoran los \"FutureWarnings\" molestos\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cvs file and generate copy\n",
    "DATASET_PATH = 'weatherAUS.csv'\n",
    "dataset = pd.read_csv(DATASET_PATH)\n",
    "dataset_=dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el dataset va entre la fecha 2008-12-1 y la fecha 2017-6-25\n"
     ]
    }
   ],
   "source": [
    "# Observamos si hay fechas faltantes, ya que RainToday no coincide con RainTomorrow (deberían diferenciarse como máximo en 2 valores)\n",
    "\n",
    "if 'Date' in dataset_.columns: dataset_ = dataset_.set_index('Date')\n",
    "dataset_.index = pd.to_datetime(dataset_.index)\n",
    "first_date = str(dataset_.index[0].year) + '-' + str(dataset_.index[0].month) + '-' + str(dataset_.index[0].day) \n",
    "last_date = str(dataset_.index[-1].year) + '-' + str(dataset_.index[-1].month) + '-' + str(dataset_.index[-1].day) \n",
    "print('el dataset va entre la fecha {} y la fecha {}'.format(first_date, last_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entre las fechas 2008-12-01 y 2017-06-24 hay 89 fechas faltantes en el dataset\n",
      "\n",
      " las fechas son: DatetimeIndex(['2011-04-01', '2011-04-02', '2011-04-03', '2011-04-04',\n",
      "               '2011-04-05', '2011-04-06', '2011-04-07', '2011-04-08',\n",
      "               '2011-04-09', '2011-04-10', '2011-04-11', '2011-04-12',\n",
      "               '2011-04-13', '2011-04-14', '2011-04-15', '2011-04-16',\n",
      "               '2011-04-17', '2011-04-18', '2011-04-19', '2011-04-20',\n",
      "               '2011-04-21', '2011-04-22', '2011-04-23', '2011-04-24',\n",
      "               '2011-04-25', '2011-04-26', '2011-04-27', '2011-04-28',\n",
      "               '2011-04-29', '2011-04-30', '2012-12-01', '2012-12-02',\n",
      "               '2012-12-03', '2012-12-04', '2012-12-05', '2012-12-06',\n",
      "               '2012-12-07', '2012-12-08', '2012-12-09', '2012-12-10',\n",
      "               '2012-12-11', '2012-12-12', '2012-12-13', '2012-12-14',\n",
      "               '2012-12-15', '2012-12-16', '2012-12-17', '2012-12-18',\n",
      "               '2012-12-19', '2012-12-20', '2012-12-21', '2012-12-22',\n",
      "               '2012-12-23', '2012-12-24', '2012-12-25', '2012-12-26',\n",
      "               '2012-12-27', '2012-12-28', '2012-12-29', '2012-12-30',\n",
      "               '2012-12-31', '2013-02-01', '2013-02-02', '2013-02-03',\n",
      "               '2013-02-04', '2013-02-05', '2013-02-06', '2013-02-07',\n",
      "               '2013-02-08', '2013-02-09', '2013-02-10', '2013-02-11',\n",
      "               '2013-02-12', '2013-02-13', '2013-02-14', '2013-02-15',\n",
      "               '2013-02-16', '2013-02-17', '2013-02-18', '2013-02-19',\n",
      "               '2013-02-20', '2013-02-21', '2013-02-22', '2013-02-23',\n",
      "               '2013-02-24', '2013-02-25', '2013-02-26', '2013-02-27',\n",
      "               '2013-02-28'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "fechas_faltantes = pd.date_range(start=first_date, end=last_date).difference(dataset_.index)\n",
    "print('entre las fechas 2008-12-01 y 2017-06-24 hay {} fechas faltantes en el dataset'.format(len(fechas_faltantes)))\n",
    "print('\\n las fechas son:', fechas_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de fechas faltantes en los años: \n",
      " 2012    31\n",
      "2011    30\n",
      "2013    28\n",
      "dtype: int64\n",
      "cantidad de fechas faltantes en los meses: \n",
      " 12    31\n",
      "4     30\n",
      "2     28\n",
      "dtype: int64\n",
      "cantidad de fechas faltantes en los días: \n",
      " 1     3\n",
      "2     3\n",
      "28    3\n",
      "27    3\n",
      "26    3\n",
      "25    3\n",
      "24    3\n",
      "23    3\n",
      "22    3\n",
      "21    3\n",
      "20    3\n",
      "19    3\n",
      "18    3\n",
      "17    3\n",
      "16    3\n",
      "15    3\n",
      "14    3\n",
      "13    3\n",
      "12    3\n",
      "11    3\n",
      "10    3\n",
      "9     3\n",
      "8     3\n",
      "7     3\n",
      "6     3\n",
      "5     3\n",
      "4     3\n",
      "3     3\n",
      "29    2\n",
      "30    2\n",
      "31    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contamos cuantas fechas faltantes hay en cada año, mes y día para ver algún patrón\n",
    "fechas_faltantes_A = fechas_faltantes.year.value_counts()\n",
    "fechas_faltantes_M = fechas_faltantes.month.value_counts()\n",
    "fechas_faltantes_D = fechas_faltantes.day.value_counts()\n",
    "print('cantidad de fechas faltantes en los años: \\n', fechas_faltantes_A)\n",
    "print('cantidad de fechas faltantes en los meses: \\n',fechas_faltantes_M)\n",
    "print('cantidad de fechas faltantes en los días: \\n',fechas_faltantes_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A PARTIR DE ACÁ SE HACEN LAS TRANSFORMACIONES PARA EL POSTERIOR ANÁLISIS DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierte la columna de fecha en dos columnas :año y día (entre 1 y 13).\n",
    "dataset__=TP.date2columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos con los años 2014, 2015 y 2016 que son los que tienen todas los días \n",
    "dataset__=dataset__[np.logical_or(np.logical_or(dataset__[\"Year\"]==2014,dataset__[\"Year\"]==2017), np.logical_or(dataset__[\"Year\"]==2015, dataset__[\"Year\"]==2016))]\n",
    "dataset__=dataset__.reset_index(inplace=False).drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2014, 2015, 2016, 2017], dtype=uint16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset__['Year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las filas con datos faltantes de RainToday (mismas que faltantes en Rainfall)\n",
    "# dataset__=dataset__[dataset__[\"RainToday\"].notnull()]\n",
    "# Se eliminan las filas con datos faltantes de RainTomorrow, que es nuestra variable de salida\n",
    "# dataset__=dataset__[dataset__[\"RainTomorrow\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year porcentaje de Null 0.0\n",
      "MonthDay porcentaje de Null 0.0\n",
      "Location porcentaje de Null 0.0\n",
      "MinTemp porcentaje de Null 1.3910504275835514\n",
      "MaxTemp porcentaje de Null 1.2915750798209442\n",
      "Rainfall porcentaje de Null 2.7548253565870326\n",
      "Evaporation porcentaje de Null 52.194073194602666\n",
      "Sunshine porcentaje de Null 59.33864938148796\n",
      "WindGustDir porcentaje de Null 6.18030709002519\n",
      "WindGustSpeed porcentaje de Null 6.143404944887449\n",
      "WindDir9am porcentaje de Null 6.892678935292891\n",
      "WindDir3pm porcentaje de Null 3.754392157491938\n",
      "WindSpeed9am porcentaje de Null 1.0380733871355912\n",
      "WindSpeed3pm porcentaje de Null 3.0997801915702663\n",
      "Humidity9am porcentaje de Null 1.9429781635567251\n",
      "Humidity3pm porcentaje de Null 5.0844738235435685\n",
      "Pressure9am porcentaje de Null 11.678726715548638\n",
      "Pressure3pm porcentaje de Null 11.656264540247404\n",
      "Cloud9am porcentaje de Null 41.606366422256805\n",
      "Cloud3pm porcentaje de Null 45.64474465320006\n",
      "Temp9am porcentaje de Null 1.2386285237537504\n",
      "Temp3pm porcentaje de Null 4.368893096089977\n",
      "RainToday porcentaje de Null 2.7548253565870326\n",
      "RainTomorrow porcentaje de Null 2.762847562051759\n"
     ]
    }
   ],
   "source": [
    "#Se verifican los null para cada columna \n",
    "#(en este caso particular busqueda ne null y de nan arrojan el mismo resultado)\n",
    "\n",
    "for column in dataset__:\n",
    "   tot=dataset__[column].isnull().sum()\n",
    "   print(column,\"porcentaje de Null\",tot/len(dataset__[column])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizamos las variables de temperatura, para hacer una imputación multivariada y eliminar las que tienen mayor cantidad de NANS y tienen alta correlación con sus pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de filas con valores nulos simultaneos de MinTemp y Temp9am es 732 \n",
      "cantidad de filas con valores nulos simultaneos de MaxTemp y Temp3pm es 709 \n",
      "cantidad de filas con valores de MaxTemp nulos es 805 \n"
     ]
    }
   ],
   "source": [
    "# Vemos que cantidad de valores nulos de manera simultánea tienen las variables de alta correlación\n",
    "aux = dataset__[np.logical_and(dataset__['MinTemp'].isnull() , dataset__['Temp9am'].isnull())]\n",
    "print('cantidad de filas con valores nulos simultaneos de MinTemp y Temp9am es {} '.format(len(aux)))\n",
    "\n",
    "aux = dataset__[np.logical_and(dataset__['MaxTemp'].isnull() , dataset__['Temp3pm'].isnull())]\n",
    "print('cantidad de filas con valores nulos simultaneos de MaxTemp y Temp3pm es {} '.format(len(aux)))\n",
    "\n",
    "aux = dataset__[np.logical_and(dataset__['MaxTemp'].isnull() , True)]\n",
    "print('cantidad de filas con valores de MaxTemp nulos es {} '.format(len(aux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizamos el método multivariado de MICE para imputar valores faltantes mediante la función generada en TP_WeatherAUS-py:  \"impute_column(df, col_to_predict, feature_columns)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de la variable previo a la imputación MaxTemp: 23.77882546081077\n",
      "61522\n",
      "805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aulamultimedia\\anaconda3\\envs\\vision1\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aulamultimedia\\MEGA\\Especializacion en Inteligencia Artificial UBA\\Materias\\Bimestre 2\\Analisis de datos\\TP\\analisis_datos_TP\\TP_WeatherAUS.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3[col_to_predict].iloc[pred_rows_idx] = model.predict(X_pred.values)#.reshape(1,-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de la variable posterior a la imputación MaxTemp: 23.78027458129495\n"
     ]
    }
   ],
   "source": [
    "# Imputamos los valores faltantes a la variable MaxTemp, teniendo en cuenta las otras variables de temperatura\n",
    "\n",
    "col_to_impute = 'MaxTemp'\n",
    "print('Media de la variable previo a la imputación {}: {}'.format(col_to_impute, np.mean(dataset__[col_to_impute])))\n",
    "feature_cols = ['MinTemp', 'Temp9am', 'Temp3pm']\n",
    "datasetIMP = TP.impute_column(dataset__, col_to_impute, feature_cols)\n",
    "print('Media de la variable posterior a la imputación {}: {}'.format(col_to_impute, np.mean(datasetIMP[col_to_impute])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de filas con valores de MaxTemp nulos es 0 \n"
     ]
    }
   ],
   "source": [
    "aux = datasetIMP[np.logical_and(datasetIMP['MaxTemp'].isnull() , True)]\n",
    "print('cantidad de filas con valores de MaxTemp nulos es {} '.format(len(aux)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33d53ad9bafa15b4e4ed06471be2976fa3b35495f0065b4cdfb4cf192edc667"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('vision1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
